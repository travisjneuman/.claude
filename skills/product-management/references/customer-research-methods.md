# Customer Research Methods

Detailed methodologies for product discovery and validation research.

## User Interview Framework

### Interview Structure (60 minutes)

**1. RAPPORT (5 min)**
- Introduction
- Thank them
- Set expectations
- Explain purpose
- Get consent for recording

**2. CONTEXT (10 min)**
- Background questions
- Current behavior and workflows
- Goals and challenges
- Pain points overview

**3. EXPLORATION (20 min)**
- Deep dive on topic
- Specific experiences: "Tell me about the last time..."
- Pain points and needs
- Current solutions and workarounds

**4. TESTING (15 min)**
- Show concepts/prototypes
- Gather reactions
- Probe for feedback
- Alternative solutions

**5. WRAP-UP (5 min)**
- "Anything else I should have asked?"
- Thank you
- Follow-up permissions
- Next steps

### Question Types and Techniques

**Open-Ended Questions:**
- "Tell me about..." (not "Do you like...")
- "Walk me through..." (specific examples)
- "How do you currently..." (actual behavior)
- "What was going through your mind when..." (decision process)

**Probing Questions:**
- "Why is that?"
- "Can you give me an example?"
- "What did you try next?"
- "How did that make you feel?"

**Avoid:**
- Leading questions: "Don't you think this is better?"
- Future intentions: "Would you use this?"
- Hypotheticals without context
- Pitching your solution
- Asking for feature requests

### Analysis Process

1. **Immediate Debrief**: Write observations within 1 hour
2. **Thematic Coding**: Identify patterns across 3+ interviews
3. **Insight Synthesis**: Group findings into themes
4. **Validation**: Look for disconfirming evidence
5. **Prioritization**: Weight by frequency and severity

## Persona Development

### Persona Template

**NAME & PHOTO**

**DEMOGRAPHICS:**
- Role/Title
- Company size/type
- Industry
- Experience level
- Location

**GOALS:**
- What are they trying to achieve?
- Success criteria
- Motivations

**FRUSTRATIONS:**
- What gets in their way?
- Current pain points
- Workarounds they use

**BEHAVIORS:**
- How do they work?
- What tools do they use?
- Decision-making process
- Information sources

**PSYCHOGRAPHICS:**
- Attitudes and values
- Preferences
- Communication style

**REPRESENTATIVE QUOTE:**
"[Statement that captures their perspective]"

**A DAY IN THE LIFE:**
[Narrative scenario describing typical workflow and challenges]

**RELATIONSHIP TO PRODUCT:**
- How would they discover it?
- What would trigger adoption?
- How often would they use it?
- What value would they get?

### Persona Creation Process

1. **Research Phase** (5-15 interviews per segment)
   - User interviews
   - Observational research
   - Analytics data
   - Survey data

2. **Pattern Identification**
   - Group similar behaviors
   - Identify distinct segments
   - Find meaningful differences

3. **Persona Development**
   - Create 3-5 primary personas
   - Include demographics, goals, behaviors
   - Make them memorable and specific
   - Avoid stereotypes

4. **Validation**
   - Share with stakeholders
   - Test against real users
   - Refine based on feedback

5. **Socialization**
   - Create poster/handout versions
   - Present to team
   - Use in decision-making
   - Update as you learn

## Survey Design

### Question Types

**Multiple Choice:**
- Easy to analyze
- Limited insight depth
- Good for demographics, preferences
- Randomize order to prevent bias

**Likert Scale:**
- Measure intensity (1-5 or 1-7)
- 5-point: Strongly disagree to Strongly agree
- 7-point: More granularity
- Always include neutral option

**Rating Scale:**
- 0-10 rating
- Good for NPS, satisfaction
- Visual sliders for continuous

**Open-Ended:**
- Rich qualitative insights
- Harder to analyze
- Use sparingly (2-3 max)
- Ask "Why?" for context

**Ranking:**
- Force prioritization
- Max 5-7 items
- Drag-and-drop interface

### Best Practices

**Question Design:**
- One concept per question
- Avoid double-barreled: "Is it fast and easy?"
- No leading questions
- Use simple language
- Avoid jargon
- Be specific, not vague

**Survey Structure:**
- Start with easy, engaging questions
- Group related topics
- Most important questions first
- Demographics at end
- Keep under 10 minutes
- Progress bar for long surveys

**Quality Control:**
- Include attention checks
- "Please select 'Strongly Agree' for this question"
- Screen out speeders (too fast completion)
- Check for straight-lining (all same answer)
- Remove incomplete responses

**Sample Size:**
- 100+ per segment for statistical significance
- 384+ for representative sample (95% confidence, 5% margin)
- More for small effect sizes
- Consider response rate (10-30% typical)

## Usability Testing

### Test Protocol

**Pre-Test:**
- Recruit representative users (5-8 per iteration)
- Prepare scenarios and tasks
- Set up recording tools
- Test the test (pilot run)

**Introduction (5 min):**
- Explain purpose
- "We're testing the design, not you"
- Think-aloud protocol
- Permission to record

**Tasks (30-40 min):**
- Present realistic scenarios
- "You want to [goal], show me how you would do that"
- Observe without helping
- Note struggles and confusion
- Ask clarifying questions only

**Debrief (10-15 min):**
- Overall impressions
- Specific feedback on confusing areas
- Comparison to alternatives
- Feature requests and suggestions

**Post-Test:**
- Thank participant
- Provide incentive
- Document findings immediately

### Metrics to Capture

**Quantitative:**
- Task success rate (completed successfully)
- Time on task
- Error rate
- Clicks to completion
- Satisfaction rating (SUS score)

**Qualitative:**
- Confusion points
- Expectations vs. reality
- Mental models
- Emotional reactions
- Verbal feedback

### Analysis

**Identify Patterns:**
- 3+ users experiencing same issue = high priority
- Categorize issues by severity:
  - Critical: Prevents task completion
  - Serious: Causes significant difficulty
  - Minor: Causes slight inconvenience

**Prioritization:**
- Frequency Ã— Severity
- Quick wins vs. major redesigns
- Impact on key workflows

## Jobs-to-be-Done Deep Dive

### Job Statement Format

**Template:**
"When [situation], I want to [motivation], so I can [expected outcome]."

**Examples:**
- "When I'm planning my week, I want to see all my commitments in one place, so I can avoid overcommitting."
- "When a customer asks a question, I want to quickly find the answer, so I can respond professionally and maintain trust."

### Job Types

**Functional Jobs:**
- Tasks to complete
- Problems to solve
- Example: "Process payroll accurately"

**Emotional Jobs:**
- How users want to feel
- Example: "Feel confident in my decisions"

**Social Jobs:**
- How users want to be perceived
- Example: "Be seen as knowledgeable by peers"

### Forces of Progress

**Push Forces (Current pain):**
- What's frustrating about current solution?
- What triggers desire to change?
- What problems are tolerable vs. intolerable?

**Pull Forces (New solution attraction):**
- What appeals about new solution?
- What value does it promise?
- What differentiates it?

**Anxiety Forces (Concerns about switching):**
- What could go wrong?
- What will I lose?
- Can I trust this?
- Is it worth the effort?

**Habit Forces (Comfort with status quo):**
- Current solution is familiar
- Switching costs (time, money, learning)
- "Good enough" mindset
- Risk aversion

### JTBD Interview Approach

**Structure:**
1. "Tell me about the last time you [job]"
2. "What were you trying to accomplish?"
3. "What did you try first? How did that go?"
4. "Then what did you do?"
5. "What was frustrating about that?"
6. "How did you eventually solve it?"
7. "What would be your ideal solution?"

**Focus on:**
- Specific past experiences, not hypotheticals
- The struggle and context
- Alternatives considered
- Evaluation criteria used
- Compromises made

## Concept Testing Methods

### Landing Page Tests
- Create landing page describing product
- Drive traffic (ads, outreach)
- Measure sign-up rate as demand signal
- Threshold: 20-40% email capture = strong interest

### Fake Door Tests
- Add non-functional feature to UI
- Track click-through rate
- Show "Coming soon" message
- Measure interest before building

### Prototype Testing
- Interactive mockups (Figma, InVision)
- Simulate real functionality
- Usability test with users
- Iterate quickly

### Wizard of Oz Testing
- Manual backend, real frontend
- Simulate automation with humans
- Test concept before technical build
- Example: Concierge MVP, manual processing

### Evaluation Criteria

**Comprehension:**
- Do they understand what it is?
- Can they explain it back?
- Do they see the value?

**Relevance:**
- Does it solve their problem?
- Is timing right?
- Does it fit their workflow?

**Differentiation:**
- How is it better than alternatives?
- What's unique about it?
- Would they switch?

**Intent:**
- Would they use it?
- Would they pay for it?
- Would they recommend it?
- How urgently do they need it?
